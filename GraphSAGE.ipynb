{"cells":[{"cell_type":"markdown","metadata":{"id":"wGfAj_JE8T-Q"},"source":[" GraphSage (Sample and Aggregate) algorithm is an inductive (it can generalize to unseen nodes) deep learning method developed by Hamilton, Ying, and Leskovec (2017) for graphs used to generate low-dimensional vector representations for nodes. This is in contrast with the previous graph machine learning methods like Graph Convolutional Networks or DeepWalk which are inherently transductive i.e they can only generate embeddings for the nodes present in the fixed graph during the training.\n","This implies that, if in future the graph evolves and new nodes (unseen during the training) make their way into the graph then we need to retrain the whole graph in order to compute the embeddings for the new node. This limitation makes the transductive approaches inefficient to get applied on the ever evolving graphs (like social networks, protein-protein networks, etc) because of their inability to generalize on unseen nodes. The other main limitation of transductive approaches is that they cannot leverage the node features e.g text attributes, node profile information, node degrees, etc.\n","On the other hand, the GraphSage algorithm exploits both the rich node features and the topological structure of each node’s neighborhood simultaneously to efficiently generate representations for new nodes without retraining."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17822,"status":"ok","timestamp":1645026401775,"user":{"displayName":"alireza samadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1rvUsWUWglw4bHdIjOXTa4XhrFtdw1wUpGtsY=s64","userId":"15397229150758724266"},"user_tz":-60},"id":"-XkOoay0egzX","outputId":"c2fa070c-4da6-4730-c8d3-cd1fe73c769e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/ubuntu/workspace/GNNs-on-Biological-data/DATA\n"]}],"source":["%cd DATA"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xN9GY54lQeDR"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from torch_geometric.data import NeighborSampler\n","from torch_geometric.nn import SAGEConv\n","import os.path as osp\n","import pandas as pd\n","import numpy as np\n","import collections\n","from pandas.core.common import flatten\n","import random\n","import time\n","\n","from pandas.core.common import flatten\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","sns.set(rc={'figure.figsize':(16.7,8.27)})\n","sns.set_theme(style=\"ticks\")\n","import collections\n","from scipy.special import softmax\n","import umap\n","\n","from torch_geometric.data import InMemoryDataset\n","from sklearn.model_selection import train_test_split\n","import torch_geometric.transforms as T\n","import networkx as nx\n","import torch\n","from torch_geometric.data import Data"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"fMS9QXiA2WS3"},"outputs":[],"source":["def attribute_counter(G):\n","  zeros=0\n","  ones=0\n","  for node in tqdm(list(G.nodes())):\n","    if G.nodes[node]['label']==0:\n","      zeros+=1\n","    else:\n","      ones+=1\n","  print(\"#zeros: \", zeros)\n","  print(\"#ones: \", ones)\n","  print(\"portion of ones \" ,ones/(ones+zeros) )"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["disease_name = \"Schizophrenia\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":454,"status":"ok","timestamp":1645026764343,"user":{"displayName":"alireza samadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1rvUsWUWglw4bHdIjOXTa4XhrFtdw1wUpGtsY=s64","userId":"15397229150758724266"},"user_tz":-60},"id":"mYpfO1F22uOj","outputId":"befd0cd4-3bc1-4ec3-eb65-41ec12a3d799"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_706079/1036438151.py:2: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n","\n","  print(nx.info(balanced_G))\n"]},{"name":"stdout","output_type":"stream","text":["Graph with 1329 nodes and 7900 edges\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1329/1329 [00:00<00:00, 2876279.68it/s]"]},{"name":"stdout","output_type":"stream","text":["#zeros:  314\n","#ones:  1015\n","portion of ones  0.763732129420617\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["balanced_G = nx.read_gpickle(f\"{disease_name}_balanced_more.gpickle\")\n","print(nx.info(balanced_G))\n","attribute_counter(balanced_G)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"eIQoc1_Z2xrj"},"outputs":[],"source":["G=balanced_G"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Bac4WvtyQ794"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_706079/2791777853.py:5: DeprecationWarning: \n","\n","The scipy.sparse array containers will be used instead of matrices\n","in Networkx 3.0. Use `to_scipy_sparse_array` instead.\n","  adj = nx.to_scipy_sparse_matrix(G).tocoo() #coordinate format\n"]}],"source":["# retrieve the labels for each node, the nodes that are not zero\n","labels = np.asarray([G.nodes[i]['label'] != 0 for i in G.nodes]).astype(np.int64)\n","\n","# create edge index. We need to have data as previously shown. We can exploit networkX and scipy for that \n","adj = nx.to_scipy_sparse_matrix(G).tocoo() #coordinate format\n","#print(adj)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"gpmFSYkTQ-Nd"},"outputs":[],"source":["#create edge index in the proper way\n","row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long) #create a torch tensor from numpy in long format : for row indexes\n","col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long) #                                                   for column indexes\n","edge_index = torch.stack([row, col], dim=0)\n","#display(edge_index)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"NBQFZ4joQ_-K"},"outputs":[{"name":"stdout","output_type":"stream","text":["1329\n","[[ 1.75713634]\n"," [ 3.30852095]\n"," [ 4.45954824]\n"," ...\n"," [ 0.00557307]\n"," [-0.54491824]\n"," [ 0.25579639]]\n"]}],"source":["# using degree as embedding. For simplicity, the feature vector describing the \n","# will be just its degree, which is enough for us   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>.. can i use other embeddings? https://medium.com/@st3llasia/graph-embedding-techniques-7d5386c88c5\n","#is it actually working or we do it for simplicity\n","embeddings = np.array(list(dict(G.degree()).values())) #list the values of degree of each node as numpy array\n","# normalizing degree values\n","from sklearn.preprocessing import StandardScaler\n","scale = StandardScaler()\n","embeddings = scale.fit_transform(embeddings.reshape(-1,1))\n","print(len(embeddings))\n","print(embeddings)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"C6mJIqKMRDWZ"},"outputs":[],"source":["# custom pytorch dataset\n","class PPIDATASET(InMemoryDataset):\n","    def __init__(self, transform=None):\n","        super(PPIDATASET, self).__init__('.', transform, None, None) #pre transform and pre filter: None, we don't need them\n","        data = Data(edge_index=edge_index) #Data : A data object describing a homogeneous graph.  for more : https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data\n","        data.num_nodes = G.number_of_nodes()\n","        # embedding \n","        data.x = torch.from_numpy(embeddings).type(torch.float32)\n","        # labels\n","        y = torch.from_numpy(labels).type(torch.long)\n","        data.y = y.clone().detach() #removing tensors computational graph for efficency since it is not needed\n","        data.num_classes = 2\n","        # splitting the data into train, validation and test\n","        train_ratio = 0.70\n","        validation_ratio = 0.15\n","        test_ratio = 0.15\n","        X_train, X_test, y_train, y_test = train_test_split(pd.Series(G.nodes()),  pd.Series(labels), test_size=0.30, random_state=42)\n","        n_nodes = G.number_of_nodes()\n","        # create train and test masks for data\n","        # the Data objects holds a label for each node, and additional node-level attributes: train_mask, val_mask and test_mask, where\n","        #train_mask denotes against which nodes to train (140 nodes),\n","        #val_mask denotes which nodes to use for validation, e.g., t\n","        #test_mask denotes against which nodes to test \n","        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n","        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n","        train_mask[X_train.index] = True\n","        test_mask[X_test.index] = True\n","        data['train_mask'] = train_mask\n","        data['test_mask'] = test_mask\n","        data['X_train']=X_train\n","        data['X_test']=X_test\n","        data['y_test']=y_test\n","        #data['y_train']=y_train\n","        #data['y_test']=X_test\n","        self.data, self.slices = self.collate([data])\n","    # def _download(self):\n","    #     return\n","    # def _process(self):\n","    #     return\n","    # def __repr__(self):\n","    #     return '{}()'.format(self.__class__.__name__)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"H64G1SBgRFsN"},"outputs":[],"source":["dataset = PPIDATASET()\n","#Here, the dataset contains only a single, undirected citation graph, reminder: dataset is like a dictionary that hold the graph inside, here the dictionary\n","#has only one elemetns:\n","data = dataset[0] #now data is ready for training and testing"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"oDXVTrjOJkWT"},"outputs":[],"source":["split_idx={}\n","split_idx['test']=torch.tensor(sorted(data.X_test.index.values))\n","split_idx['train']=torch.tensor(sorted(data.X_train.index.values))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"1PHmWmAXcW3R"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training nodes: 930\n","Number of test nodes: 399\n"]}],"source":["# lets check the node ids distribution of train, test and val\n","print('Number of training nodes:', split_idx['train'].size(0))\n","print('Number of test nodes:', split_idx['test'].size(0))"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"fejDQInCerfA"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nodes in the graph: 1329\n","Number of edges in the graph: 15445\n","Node feature matrix with shape: torch.Size([1329, 1])\n","Graph connectivity in COO format with shape: torch.Size([2, 15445])\n","Target to train against : torch.Size([1329])\n","Node feature length 1\n"]}],"source":["# lets check some graph statistics of ppi graph\n","print(\"Number of nodes in the graph:\", data.num_nodes)\n","print(\"Number of edges in the graph:\", data.num_edges)\n","print(\"Node feature matrix with shape:\", data.x.shape) # [num_nodes, num_node_features]\n","print(\"Graph connectivity in COO format with shape:\", data.edge_index.shape) # [2, num_edges]\n","print(\"Target to train against :\", data.y.shape) \n","print(\"Node feature length\", dataset.num_features)\n"]},{"cell_type":"markdown","metadata":{"id":"0Lp8bCAOztke"},"source":["## Neighborhood Sampling\n","\n","This module iteratively samples neighbors (at each layer) and constructs bipartite graphs that simulate the actual computation flow of GNNs.\n","\n","sizes: denotes how much neighbors we want to sample for each node in each layer.\n","\n","`NeighborSampler` holds the current\n","    :obj:`batch_size`, the IDs :obj:`n_id` of all nodes involved in the\n","    computation, and a list of bipartite graph objects via the tuple\n","    :obj:`(edge_index, e_id, size)`, where :obj:`edge_index` represents the\n","    bipartite edges between source and target nodes, :obj:`e_id` denotes the\n","    IDs of original edges in the full graph, and :obj:`size` holds the shape\n","    of the bipartite graph.\n","\n","The actual computation graphs are then returned in reverse-mode, meaning\n","    that we pass messages from a larger set of nodes to a smaller one, until we\n","    reach the nodes for which we originally wanted to compute embeddings.\n","\n","To refer in detail: https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/data/sampler.html"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1645026765204,"user":{"displayName":"alireza samadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1rvUsWUWglw4bHdIjOXTa4XhrFtdw1wUpGtsY=s64","userId":"15397229150758724266"},"user_tz":-60},"id":"IM7pscvyMoAC","outputId":"e6f72ac9-6de1-4631-ec56-3b7a35a748de"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/anaconda3/envs/pytorch112/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.NeighborSampler' is deprecated, use 'loader.NeighborSampler' instead\n","  warnings.warn(out)\n"]}],"source":["train_idx = split_idx['train']\n","train_loader = NeighborSampler(data.edge_index, node_idx=train_idx,\n","                               sizes=[15, 10, 5], batch_size=64,\n","                               shuffle=True)\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["test_idx = split_idx['test']\n","test_loader = NeighborSampler(data.edge_index, node_idx=test_idx,\n","                               sizes=[15, 10, 5], batch_size=64,\n","                               shuffle=False)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from torch.nn import BatchNorm1d\n","\n","class SAGE(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3):\n","        super(SAGE, self).__init__()\n","\n","        self.num_layers = num_layers\n","\n","        self.convs = torch.nn.ModuleList()\n","        self.batch_norms = torch.nn.ModuleList()\n","\n","        self.convs.append(SAGEConv(in_channels, hidden_channels))\n","        self.batch_norms.append(BatchNorm1d(hidden_channels))\n","\n","        for _ in range(num_layers - 2):\n","            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n","            self.batch_norms.append(BatchNorm1d(hidden_channels))\n","        \n","        self.convs.append(SAGEConv(hidden_channels, out_channels))\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","        for bn in self.batch_norms:\n","            bn.reset_parameters()\n","\n","    def forward(self, x, adjs):\n","        layer_embeddings = []\n","\n","        for i, (edge_index, _, size) in enumerate(adjs):\n","            x_target = x[:size[1]]  # Target nodes are always placed first.\n","            # print(\"shape of x_target\", x_target.shape)\n","            x = self.convs[i]((x, x_target), edge_index)\n","\n","            # print(\"shape of x\", x.shape)\n","            if i != self.num_layers - 1:\n","                x = self.batch_norms[i](x)\n","                x = F.relu(x)\n","                x = F.dropout(x, p=0.5, training=self.training)\n","            \n","            # if i > 0:  # Add residual connection\n","            #     x = x + layer_embeddings[-1]\n","\n","            # print(x.shape)\n","            layer_embeddings.append(x)\n","\n","        return tuple(layer_embeddings)\n","\n","    def inference(self, x_all, subgraph_loader, device):\n","        \n","        pbar = tqdm(total=140)\n","        pbar.set_description('Evaluating')\n","\n","        layer_embeddings = []\n","        \n","        xs = []\n","        for batch_size, n_id, adjs in subgraph_loader:\n","            adjs = [adj.to(device) for adj in adjs]\n","            # edge_index, _, size = adjs\n","            \n","            # for l in range(len(size)):\n","            #     size[l] = torch.tensor( [item.cpu().detach().numpy() for item in size[l]] )\n","            x = x_all[n_id]\n","\n","            for i, (edge_index, _, size) in enumerate(adjs):\n","                x_target = x[:size[1]]  # Target nodes are always placed first.\n","                x = self.convs[i]((x, x_target), edge_index)\n","\n","                if i != self.num_layers - 1:\n","                    x = self.batch_norms[i](x)\n","                    x = F.relu(x)\n","                    x = F.dropout(x, p=0.5, training=self.training)\n","            \n","            xs.append(x)\n","            pbar.update(batch_size)\n","\n","        x_all = torch.cat(xs, dim=0)\n","\n","        layer_embeddings = x_all\n","                \n","        pbar.close()\n","\n","        return layer_embeddings"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"v-asAT9lMyrq"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = SAGE(dataset.num_features, 512, dataset.num_classes, num_layers=3)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"MA0OcJRVM55J"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1329, 1])\n"]}],"source":["# loading node feature matrix and node labels\n","x = data.x.to(device)\n","print(x.shape)\n","y = data.y.squeeze().to(device)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"HIYgvHluM9xD"},"outputs":[],"source":["def train(epoch):\n","    model.train()\n","\n","    #pbar = tqdm(total=train_idx.size(0))\n","    #pbar.set_description(f'Epoch {epoch:02d}')\n","\n","    total_loss = total_correct = 0\n","    for batch_size, n_id, adjs in train_loader:\n","        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n","        # print(len(n_id))\n","        adjs = [adj.to(device) for adj in adjs]\n","        optimizer.zero_grad()\n","        # print(x[n_id].shape)  \n","        # print(len(adjs))  \n","        l1_emb, l2_emb, l3_emb = model(x[n_id], adjs=adjs)\n","        #print(\"Layer 1 embeddings\", l1_emb.shape)\n","        #print(\"Layer 2 embeddings\", l2_emb.shape)\n","        out = l3_emb.log_softmax(dim=-1)\n","        loss = F.cross_entropy(out, y[n_id[:batch_size]])\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += float(loss)\n","        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n","        #pbar.update(batch_size)\n","\n","    #pbar.close()\n","\n","    loss = total_loss / len(train_loader)\n","    approx_acc = total_correct / train_idx.size(0)\n","\n","    return loss, approx_acc"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40177,"status":"ok","timestamp":1645026848582,"user":{"displayName":"alireza samadi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1rvUsWUWglw4bHdIjOXTa4XhrFtdw1wUpGtsY=s64","userId":"15397229150758724266"},"user_tz":-60},"id":"Y6COcCs1NBcK","outputId":"c5bedeb5-d527-4ce2-f9cd-203f2793fde9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 01, Loss: 0.6074, Approx. Train: 0.7032\n","Epoch 02, Loss: 0.6036, Approx. Train: 0.7366\n","Epoch 03, Loss: 0.6025, Approx. Train: 0.7333\n","Epoch 04, Loss: 0.6051, Approx. Train: 0.7376\n","Epoch 05, Loss: 0.6075, Approx. Train: 0.7344\n","Epoch 06, Loss: 0.5920, Approx. Train: 0.7398\n","Epoch 07, Loss: 0.5952, Approx. Train: 0.7226\n","Epoch 08, Loss: 0.5666, Approx. Train: 0.7462\n","Epoch 09, Loss: 0.5832, Approx. Train: 0.7366\n","Epoch 10, Loss: 0.6029, Approx. Train: 0.7409\n","Epoch 11, Loss: 0.5956, Approx. Train: 0.7290\n","Epoch 12, Loss: 0.5632, Approx. Train: 0.7419\n","Epoch 13, Loss: 0.5923, Approx. Train: 0.7419\n","Epoch 14, Loss: 0.5916, Approx. Train: 0.7387\n","Epoch 15, Loss: 0.5868, Approx. Train: 0.7430\n","Epoch 16, Loss: 0.5811, Approx. Train: 0.7366\n","Epoch 17, Loss: 0.5765, Approx. Train: 0.7441\n","Epoch 18, Loss: 0.5740, Approx. Train: 0.7301\n","Epoch 19, Loss: 0.5802, Approx. Train: 0.7505\n","Epoch 20, Loss: 0.5805, Approx. Train: 0.7473\n","Epoch 21, Loss: 0.5783, Approx. Train: 0.7430\n","Epoch 22, Loss: 0.5885, Approx. Train: 0.7462\n","Epoch 23, Loss: 0.5733, Approx. Train: 0.7366\n","Epoch 24, Loss: 0.5668, Approx. Train: 0.7430\n","Epoch 25, Loss: 0.5676, Approx. Train: 0.7419\n","Epoch 26, Loss: 0.5854, Approx. Train: 0.7355\n","Epoch 27, Loss: 0.5712, Approx. Train: 0.7473\n","Epoch 28, Loss: 0.5908, Approx. Train: 0.7355\n","Epoch 29, Loss: 0.5780, Approx. Train: 0.7409\n","Epoch 30, Loss: 0.5705, Approx. Train: 0.7398\n","Epoch 31, Loss: 0.5565, Approx. Train: 0.7441\n","Epoch 32, Loss: 0.5763, Approx. Train: 0.7355\n","Epoch 33, Loss: 0.5851, Approx. Train: 0.7344\n","Epoch 34, Loss: 0.5735, Approx. Train: 0.7473\n","Epoch 35, Loss: 0.5815, Approx. Train: 0.7323\n","Epoch 36, Loss: 0.5700, Approx. Train: 0.7376\n","Epoch 37, Loss: 0.5833, Approx. Train: 0.7430\n","Epoch 38, Loss: 0.5473, Approx. Train: 0.7581\n","Epoch 39, Loss: 0.5661, Approx. Train: 0.7387\n","Epoch 40, Loss: 0.5658, Approx. Train: 0.7290\n","Epoch 41, Loss: 0.5583, Approx. Train: 0.7505\n","Epoch 42, Loss: 0.5614, Approx. Train: 0.7462\n","Epoch 43, Loss: 0.5608, Approx. Train: 0.7484\n","Epoch 44, Loss: 0.5681, Approx. Train: 0.7398\n","Epoch 45, Loss: 0.5726, Approx. Train: 0.7484\n","Epoch 46, Loss: 0.5659, Approx. Train: 0.7452\n","Epoch 47, Loss: 0.5641, Approx. Train: 0.7538\n","Epoch 48, Loss: 0.5734, Approx. Train: 0.7430\n","Epoch 49, Loss: 0.5568, Approx. Train: 0.7559\n","Epoch 50, Loss: 0.5605, Approx. Train: 0.7430\n","Epoch 51, Loss: 0.5672, Approx. Train: 0.7430\n","Epoch 52, Loss: 0.5508, Approx. Train: 0.7484\n","Epoch 53, Loss: 0.5427, Approx. Train: 0.7516\n","Epoch 54, Loss: 0.5649, Approx. Train: 0.7495\n","Epoch 55, Loss: 0.5533, Approx. Train: 0.7505\n","Epoch 56, Loss: 0.5620, Approx. Train: 0.7452\n","Epoch 57, Loss: 0.5576, Approx. Train: 0.7441\n","Epoch 58, Loss: 0.5518, Approx. Train: 0.7387\n","Epoch 59, Loss: 0.5627, Approx. Train: 0.7409\n","Epoch 60, Loss: 0.5715, Approx. Train: 0.7430\n","Epoch 61, Loss: 0.5771, Approx. Train: 0.7398\n","Epoch 62, Loss: 0.5553, Approx. Train: 0.7419\n","Epoch 63, Loss: 0.5572, Approx. Train: 0.7527\n","Epoch 64, Loss: 0.5509, Approx. Train: 0.7538\n","Epoch 65, Loss: 0.5727, Approx. Train: 0.7452\n","Epoch 66, Loss: 0.5612, Approx. Train: 0.7441\n","Epoch 67, Loss: 0.5614, Approx. Train: 0.7398\n","Epoch 68, Loss: 0.5556, Approx. Train: 0.7484\n","Epoch 69, Loss: 0.5508, Approx. Train: 0.7473\n","Epoch 70, Loss: 0.5685, Approx. Train: 0.7462\n","Epoch 71, Loss: 0.5485, Approx. Train: 0.7441\n","Epoch 72, Loss: 0.5706, Approx. Train: 0.7430\n","Epoch 73, Loss: 0.5585, Approx. Train: 0.7419\n","Epoch 74, Loss: 0.5700, Approx. Train: 0.7409\n","Epoch 75, Loss: 0.5455, Approx. Train: 0.7538\n","Epoch 76, Loss: 0.5546, Approx. Train: 0.7527\n","Epoch 77, Loss: 0.5514, Approx. Train: 0.7462\n","Epoch 78, Loss: 0.5709, Approx. Train: 0.7452\n","Epoch 79, Loss: 0.5531, Approx. Train: 0.7516\n","Epoch 80, Loss: 0.5688, Approx. Train: 0.7344\n","Epoch 81, Loss: 0.5480, Approx. Train: 0.7452\n","Epoch 82, Loss: 0.5596, Approx. Train: 0.7430\n","Epoch 83, Loss: 0.5563, Approx. Train: 0.7527\n","Epoch 84, Loss: 0.5566, Approx. Train: 0.7516\n","Epoch 85, Loss: 0.5649, Approx. Train: 0.7484\n","Epoch 86, Loss: 0.5496, Approx. Train: 0.7505\n","Epoch 87, Loss: 0.5486, Approx. Train: 0.7462\n","Epoch 88, Loss: 0.5553, Approx. Train: 0.7387\n","Epoch 89, Loss: 0.5547, Approx. Train: 0.7452\n","Epoch 90, Loss: 0.5549, Approx. Train: 0.7441\n","Epoch 91, Loss: 0.5530, Approx. Train: 0.7548\n","Epoch 92, Loss: 0.5237, Approx. Train: 0.7613\n","Epoch 93, Loss: 0.5443, Approx. Train: 0.7484\n","Epoch 94, Loss: 0.5561, Approx. Train: 0.7516\n","Epoch 95, Loss: 0.5482, Approx. Train: 0.7548\n","Epoch 96, Loss: 0.5463, Approx. Train: 0.7462\n","Epoch 97, Loss: 0.5404, Approx. Train: 0.7516\n","Epoch 98, Loss: 0.5513, Approx. Train: 0.7484\n","Epoch 99, Loss: 0.5505, Approx. Train: 0.7548\n","Epoch 100, Loss: 0.5486, Approx. Train: 0.7495\n","training time(seconds): 8.470845460891724\n","accuracy 0.7494623655913979\n"]}],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","tick=time.time()\n","for epoch in range(1, 101):\n","    loss, acc = train(epoch)\n","    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n","tock=time.time()\n","print (\"training time(seconds):\", tock-tick)\n","print(\"accuracy\", acc)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["@torch.no_grad()\n","def test():\n","    model.eval()\n","\n","    l3_embeddings = model.inference(x, test_loader, device)\n","    out = l3_embeddings.log_softmax(dim=-1)\n","    y_true = y[test_idx].cpu().unsqueeze(-1)\n","    y_pred = out.argmax(dim=-1, keepdim=True)\n","\n","    return y_true,y_pred"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating: : 399it [00:00, 7452.80it/s]           "]},{"name":"stdout","output_type":"stream","text":["399 399\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from torchmetrics import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n","\n","accuracy = Accuracy(task='binary').to(device)\n","precision = Precision(task='binary').to(device)\n","recall = Recall(task='binary').to(device)\n","f1 = F1Score(task='binary').to(device)\n","confmat = ConfusionMatrix(task='binary').to(device)\n","\n","# shapes\n","y_true, y_pred = test()\n","print(len(y_true), len(y_pred))\n","y_true = y_true.view(-1).to(device)\n","y_pred = y_pred.view(-1).to(device)\n","\n","test_acc = accuracy(y_pred,y_true)\n","test_precision = precision(y_pred,y_true)\n","test_f1score = f1(y_pred,y_true)\n","test_recall = recall(y_pred,y_true)\n","conf_matrix = confmat(y_pred, y_true)\n","\n","TN_test, FP_test, FN_test, TP_test = conf_matrix.view(-1).tolist()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.7744361162185669\n","test precision: 0.7921052575111389\n","Test f1 score: 0.8699421882629395\n","Test recall: 0.9647436141967773\n"," #### confusion matrix test: \n","TP 301 FP 79\n","TN 8 FN 11\n"]}],"source":["print('Test Accuracy: %s' % test_acc.item())\n","print('test precision: %s' % test_precision.item())\n","print('Test f1 score: %s' % test_f1score.item())\n","print('Test recall: %s' % test_recall.item())\n","print(\" #### confusion matrix test: \")\n","print( \"TP\",TP_test,\"FP\",FP_test)\n","print(\"TN\", TN_test,\"FN\",FN_test)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["@torch.no_grad()\n","def test_train():\n","    model.eval()\n","\n","    l3_embeddings = model.inference(x, train_loader, device)\n","    out = l3_embeddings.log_softmax(dim=-1)\n","    y_true = y[train_idx].cpu().unsqueeze(-1)\n","    y_pred = out.argmax(dim=-1, keepdim=True)\n","\n","    return y_true,y_pred"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating: : 930it [00:00, 10162.90it/s]          "]},{"name":"stdout","output_type":"stream","text":["930 930\n","Train Accuracy: 0.7236559391021729\n","train precision: 0.7516930103302002\n","Train f1 score: 0.8382630348205566\n","Train recall: 0.9473684430122375\n"," #### confusion matrix train: \n","TP 666 FP 220\n","TN 7 FN 37\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["y_true, y_pred = test_train()\n","print(len(y_true), len(y_pred))\n","y_true = y_true.view(-1).to(device)\n","y_pred = y_pred.view(-1).to(device)\n","\n","train_acc = accuracy(y_pred,y_true)\n","train_precision = precision(y_pred,y_true)\n","train_f1score = f1(y_pred,y_true)\n","train_recall = recall(y_pred,y_true)\n","conf_matrix = confmat(y_pred, y_true)\n","\n","TN_train, FP_train, FN_train, TP_train = conf_matrix.view(-1).tolist()\n","\n","print('Train Accuracy: %s' % train_acc.item())\n","print('train precision: %s' % train_precision.item())\n","print('Train f1 score: %s' % train_f1score.item())\n","print('Train recall: %s' % train_recall.item())\n","print(\" #### confusion matrix train: \")\n","print( \"TP\",TP_train,\"FP\",FP_train)\n","print(\"TN\", TN_train,\"FN\",FN_train)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"m8MpI1Z7NMUq"},"outputs":[{"name":"stdout","output_type":"stream","text":["530434\n"]}],"source":["#compute the number of trainable parameters:\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","total_parameter = count_parameters(model)\n","print(total_parameter)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"rAdH88kvQSEy"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model's state_dict:\n","convs.0.lin_l.weight \t torch.Size([512, 1])\n","convs.0.lin_l.bias \t torch.Size([512])\n","convs.0.lin_r.weight \t torch.Size([512, 1])\n","convs.1.lin_l.weight \t torch.Size([512, 512])\n","convs.1.lin_l.bias \t torch.Size([512])\n","convs.1.lin_r.weight \t torch.Size([512, 512])\n","convs.2.lin_l.weight \t torch.Size([2, 512])\n","convs.2.lin_l.bias \t torch.Size([2])\n","convs.2.lin_r.weight \t torch.Size([2, 512])\n","batch_norms.0.weight \t torch.Size([512])\n","batch_norms.0.bias \t torch.Size([512])\n","batch_norms.0.running_mean \t torch.Size([512])\n","batch_norms.0.running_var \t torch.Size([512])\n","batch_norms.0.num_batches_tracked \t torch.Size([])\n","batch_norms.1.weight \t torch.Size([512])\n","batch_norms.1.bias \t torch.Size([512])\n","batch_norms.1.running_mean \t torch.Size([512])\n","batch_norms.1.running_var \t torch.Size([512])\n","batch_norms.1.num_batches_tracked \t torch.Size([])\n"]}],"source":["# Print model's state_dict\n","print(\"Model's state_dict:\")\n","for param_tensor in model.state_dict():\n","    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"lA0_fiJaqdSI"},"outputs":[],"source":["torch.save(model,f'graphsage_model_{disease_name}_lastversion')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"3.GraphSAGE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
